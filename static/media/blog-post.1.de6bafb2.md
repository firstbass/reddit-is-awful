
# Bias in Algorithms
### Author: Naseem Sani

## **Algorithms and You: How They Work**

Algorithms work behind the scenes in almost every aspect of our lives from predicting fluctuations in the stock market to anticipating what kind of cereal we might want to buy. They are also the biggest driving force in the news that we find online. Unlike the news media of the past, which was conveyed through print, electronic media can be tailored to the reader. The way this works is an algorithm can keep track of how many people clicked on an article, then try to find a common trait among those people based on their previous clicks or browsing history. Then, it will recommend similar articles to that person as well as advertise to new people the article that you clicked on if you have a similar digital footprint. Some algorithms can even write news stories given a specific set of data.

## **Algoritms and Journalism**

When examining the development and integration of algorithms into journalism, there are a few things to consider. Journalists are generally thought of as &quot;good people&quot; Rushworth Kidder (1995) able to display ethical values and use that to make difficult choices as to what they report and how they report it. In addition, this could mean adhering to certain rules of appropriateness when it is customary or choosing to break them when it is apparent that information is being withheld or is hard to get. Therefor a proper journalism algorithm would have to reflect a course of action that is not always rule based but follows a procedure that is built to handle complex situations and ambiguous outcomes (March &amp; Olsen, 1989, p. 25).

Something else to consider is the way that journalist gather information and the way computers gather information is different. Journalists will often have to submit Freedom of Information Act Requests (FOIA) in order to get data that is not as readily open to the public. In fact, most journalist consider public data to be of little interest: choosing instead to pay agencies for information that has be hidden from public view. Robot programs or &quot;bots&quot; also collect information, but the process has to be monitored and tailored to the program so that it is used in a meaningful way. In fact, much effort is required to format the data for the bot to recognize it. A big difference between conventional journalism and automated journalism is the soft skills needed to be a journalist. In the beginning of their career, journalists learn how to talk to people, how to talk to the police and how to observe events, such as a baseball game, as a reporter rather than a spectator. These are all aspects of journalism do not apply to bot made news (Linden 69).

## **Algorithms May Decide Your News**

Implementing algorithms in news firms has seen a shift in the type of work that is needed by the journalists. Some news firms such as the Associated Press have claimed that: what used to be mundane and repetitive tasks have now been automated, yielding higher accuracy rates and customer satisfaction (Powers, 2012, p. 25). The role of the journalist is now to work with computer engineers and software developers to explain the process of journalism and what the process is towards writing a good story. In addition, it is not only enough for journalists to collaborate with programmers but to also understand the algorithm's decision making process.

The business logic is that reactive journalism that capitalizes on breaking news and events costs money, the cost of which can be mitigated by building proactive editorial solutions. For example, anticipatory processes or developing software that fills the newspaper pages automatically without any human intervention, like a template that is preprogrammed. A bot then fetches and inserts the information where appropriate. One representative from Local Labs, which is a small company in Chicago, explains: &quot;If you're reactive every week, then it costs more money.&quot;(Linden 68)

With the ability to deliver the news to their audience electronically, it opens new ways of getting feedback that wasn't possible before. You can instantly track how many people opened your article and watch trends to determine what kind of news your audience prefers. Editorial decisions are increasingly being influenced by large sets of user data feedback and supported by automated algorithms making the use of bots almost mandatory for analyzing data. This means that media organizations will need to fundamentally redefine what media audiences mean to them as not just recipients of news but also influencers of it (Napoli, 2012).

## **Social Media Algorithms Aren't Your Friend**

At this point we should take a look into how algorithms can have bias, especially those used for social media work. To put it simply, algorithms track your habits and the content that you click on to build up a report on you. Then they recommend content to you based on the fact that people with similar habits and perceived interests also liked the same things as you. Before the use of algorithms most social media sites simply showed their feed of posts in reverse chronological order, where you would see everyone's posts if you scroll down far enough. With the implementation of algorithms there is now a hierarchy of which posts get seen first and which might not show up at all. To start, the posts from people or accounts that you have a lot of activity with always show up first. These are your friends, family and favorite organizations with whom you interact with the most. After that are high traffic posts with many shares and comments that might not be related to you but have a high possibility of you liking them according to your past interests. The posts are then organized based on how well they fit into those categories and are then shown in that order (Barnhart 53).

## **The Social Media Hierarchy**

There is also a hierarchy to the kinds of posts that algorithms like to promote. As stated by Facebook and Twitter (Barnhart 51), original videos made by the party that posts them are given high exposure, followed by pictures, and lastly text. Another important factor that is considered is how often the user posts content. A person who posts very frequently will have a higher algorithmic priority compared to someone who posts once in a while. In addition to promoting content that is predicted to gather high traffic, there is also a system in place to demote posts that only post links to other websites with little explanation or content surrounding them. Posts that focus too heavily on selling a product without providing interesting content can also be demoted. Frequent uses of phrases like &quot;Buy Now&quot;, can be grounds to label a post as spam, which will cause it to not appear on most people's feeds.

## **Where There's Bias, There's Issues**

A few issues arise from this. According to an article written by Michael Schudson and Katherine Fink for the _Columbia Journalism Review_, &quot;There's no opportunity for algorithmic audiences to explain why they clicked, whether they're glad they did, or whether they'd click on something similar in the future.&quot; Algorithms make it easier to sift through all the content that's on the internet, but the problem is that we only see what algorithms, and the companies that use them want us to see. Nick Diakopoulos, who is a research fellow at the Tow Center for Digital Journalism, explains that algorithms can be put into several categories based on the types of decisions they make. _Prioritization_ ranks content to bring attention to one thing at the expense of another. _Association_ marks relationships between entities, such as articles or videos that share subject matter of features. _Filtering_ involves the inclusion or exclusion of certain information based on a set of criteria.

## **Selection Bias in Algorithms**

According to an article written by Jihii Jolley for the _Columbia Journalism Review_: this type of selective exposure can result in being in a &quot;filter bubble&quot; which isolates you from opposing viewpoints. Algorithms can also popularize fringe opinions and make them more visible. These types of algorithms create a news literacy issue because in the print world, partisan media was transparent about its biases, and readers could therefore select which bias they preferred. Today however, readers don't necessarily know how algorithms are biased and how nuanced the filters they receive content through really are.

Social media algorithms especially tend to push the most viewed content without checking if it is true or not, which is why they magnify the impact of fake news. Guillaume Chaslot, one of YouTube's former engineers stated that, on YouTube in particular, conspiracy theory videos get much more traffic than accurate and properly sourced ones. In a paper published in _Information, Communication, and Society_, Richard Fletcher and Rasmus Kleis Nielsen's studies have shown that younger people tend to have more faith in how algorithms select news, adopting an &quot;if the news is important, it will find me&quot; mentality. Their studies also showed that people who are more interested in 'soft' news topics like entertainment, celebrity, arts, and sport also tend to express greater approval for news selected by algorithms.

## **The Concept of Fake News**

Although some might write off fake news as the same old inflated attention grabbing stories of the past, which news outlets like the National Enquirer are famous for, there are a few key differences. When someone picks up an issue of the National Enquirer, they know what kind of biases and allegations to expect while the same can't be said for the fake news found on the internet. In an article written by Fatemeh Asr for Simon Fraser University, she sited that a study conducted by researchers at the Massachusetts Institute of Technology, focused on the cognitive aspects of exposure to fake news and found that, on average, newsreaders believe a false news headline at least 20 percent of the time. In addition, false news stories are now spreading 10 times faster than real ones, which posses a serious threat to the way we get our information and the trustworthiness of news outlets themselves.

## **Pizzagate**

A great example of how fake news can affect our daily lives on a grand scale is the now famous case known colloquially as &quot;Pizzagate&quot;. This was a false conspiracy that began in 2016 that claimed that Hillary Clinton, who at the time was running for president, was involved in a human trafficking operation that was run out of a pizza restaurant. The name &quot;Pizzagate&quot; is homage to Nixon's famous Watergate scandal. When you first hear it, it sounds absurd to most people, but enough people believed it to the point that it had to be publicly addressed by Hilary Clinton. Unfortunately, it became popular enough to where it resulted in the owner of the restaurant receiving death threats and one believer of the conspiracy even showing up to the restaurant with a gun. This undoubtably effected some peoples' vote during the election season that year.

## **There Can Be Hope**

Even though algorithms are responsible for the rapid circulation of fake news, they might also be the solution to stopping it. Natural language scientists have began building algorithms to differentiate false news and misinformation from accurately sourced and human written news. There are two methods utilized to do this. The first is tracking down the original source of the news story and scoring the credibility of that source. The second is to analyze the type of language that is used in the news story. Certain phrases and words are more common in deceptive texts than in honestly written ones. Identifying that can help to identify the legitimacy of the story. As other algorithms, these fake news identifying ones would learn as they review more and more stories and become better at differentiating between real and fake stories. Fatemeh Asr writes that people can also look out for certain ques that are a sign of what kind of news story they are reading. For example, fake news uses words commonly used in hate speech, as well as words related to sex, death and anxiety, while honest news stories focus more on work/business and money/economy.

## **Closing Thoughts**

There are online resources that allow you to submit a body of text, then their program analyses it to see how likely what you submitted is legitimate. This however begs the question, if algorithms are to blame for the spread of fake news and sometimes for creating fake news, could you not also make an algorithm to produce content that escapes the detection of security algorithms? This could very well be like the cat and mouse game that was seen in the early 2000's between computer viruses and anti-virus software.

There are certainly ethical, moral, and operational considerations that come with the advent of software-generated news, and algorithmic popularization of content since journalistic aspects are only part of the picture. Publishers, advertisers, data producers, governments, and users all play a role and have their own agendas in the political economy of algorithm systems. We have seen already that artificial intelligence tends to concentrate power in fewer hands, Google, Facebook, and Twitter as prime examples. Algorithms can also be manipulated to an extent that is not possible with human beings, for faster and more accurate work. These are some of the fields where journalism and media researchers need to think hard about the algorithm issue, especially the impact on society (Linden 73).














__________________________

# Sources

[https://reutersinstitute.politics.ox.ac.uk/our-research/how-do-people-feel-about-news-selected-algorithms-social-media](https://reutersinstitute.politics.ox.ac.uk/our-research/how-do-people-feel-about-news-selected-algorithms-social-media)

[https://archives.cjr.org/the\_research\_report/the\_algorithm\_method.php](https://archives.cjr.org/the_research_report/the_algorithm_method.php)

[https://archives.cjr.org/news\_literacy/algorithms\_filter\_bubble.php](https://archives.cjr.org/news_literacy/algorithms_filter_bubble.php)

[https://www.researchgate.net/publication/317282903\_Algorithms\_for\_journalism\_The\_future\_of\_news\_work](https://www.researchgate.net/publication/317282903_Algorithms_for_journalism_The_future_of_news_work)

[https://phys.org/news/2018-07-fake-news-algorithms-dock.html](https://phys.org/news/2018-07-fake-news-algorithms-dock.html)

[https://www.govtech.com/computing/How-An-Algorithm-Can-Distinguish-Between-Fake-and-Real-News.html](https://www.govtech.com/computing/How-An-Algorithm-Can-Distinguish-Between-Fake-and-Real-News.html)

[https://sproutsocial.com/insights/social-media-algorithms/](https://sproutsocial.com/insights/social-media-algorithms/)